//example of some shaders compiled
flat basic.vs flat.fs
shadow basic.vs shadow.fs
texture basic.vs texture.fs
depth quad.vs depth.fs
multi basic.vs multi.fs
decal basic.vs decal.fs
deferred quad.vs deferred.fs
deferred_ws basic.vs deferred.fs
ssao quad.vs ssao.fs
blur quad.vs blur.fs
probe basic.vs probe.fs
skybox basic.vs skybox.fs
ref_probes basic.vs ref_probes.fs
tonemapper quad.vs tonemapper.fs
volumetric_directional quad.vs volumetricdir.fs
deferred_reflections quad.vs deferred_reflections.fs
planar_reflection basic.vs planar_ref.fs

\basic.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_uv;
in vec4 a_color;

uniform vec3 u_camera_pos;

uniform mat4 u_model;
uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;
out vec4 v_color;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( v_position, 1.0) ).xyz;
	
	//store the color in the varying var to use it from the pixel shader
	v_color = a_color;

	//store the texture coordinates
	v_uv = a_uv;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\quad.vs

#version 330 core

in vec3 a_vertex;
in vec2 a_uv;
out vec2 v_uv;

void main()
{	
	v_uv = a_uv;
	gl_Position = vec4( a_vertex, 1.0 );
}


\flat.fs

#version 330 core

uniform vec4 u_color;

out vec4 FragColor;

void main()
{
	
	FragColor = u_color;
}

\shadow.fs

#version 330 core

out vec4 FragColor;

void main()
{
	
	FragColor = vec4(0.0);
}


\texture.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;//material->color
uniform sampler2D u_texture;//texture
//uniform sampler2D u_emissive_texture;//texture
uniform vec3 u_emissive_factor;

uniform float u_time;
uniform float u_alpha_cutoff;//alpha threshold
uniform int u_light_type;
uniform float u_spotCutOff;
uniform float u_exponent;
uniform float u_light_maxdist;
uniform float u_light_intensity;


uniform vec3 u_camera_position;//camera->eye
uniform vec3 u_light_vector;
uniform vec3 u_light_position;
uniform vec3 u_ambient_light;
uniform vec3 u_light_color;//diffuse


uniform sampler2D shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

out vec4 FragColor;

void main()
{

	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture2D( u_texture, uv );
	if(color.a < u_alpha_cutoff)
		discard;

	if(v_world_position.y < 0.0)
		discard;

	//PHONG

	vec3 light = vec3(0.0);//here we can store the total amount of light
	light += u_ambient_light;//lets add the ambient light first
	vec3 N = normalize( v_normal );//interpolated so normalization is lost
	
	//here we store the L vector
	vec3 L;
	float spotfactor=0.0;
	float light_distance;
	
	//depending on the light type...
	
	if( u_light_type == 0 ) //directional  light
	{
		L = u_light_vector;
	}
	else //point and spot light
	{
		L = u_light_position - v_world_position;//vector from the point to the light
		light_distance = length(L);
		L = normalize(L);//we ignore the light distance for now
	}
	
	float att_factor = u_light_maxdist - light_distance;//compute a linear attenuation factor
	att_factor /= u_light_maxdist;//normalize factor
	att_factor = max( att_factor, 0.0 );//ignore negative values
	
	float NdotL = dot(N,L);//compute how much is aligned
	NdotL = clamp( NdotL, 0.0, 1.0 );//light cannot be negative (but the dot product can)
	
	light += ( NdotL * u_light_color) * att_factor;//store the amount of diffuse light

	if(u_light_type==1){ //spotlight
		
		vec3 D = normalize(u_light_vector);
		float spotCosine = dot(D,-L);
		spotCosine=clamp(spotCosine,0.0,1.0);
		
		if (spotCosine >= u_spotCutOff ) { 
			spotfactor=pow(spotCosine,u_exponent);
		}else{
			spotfactor=0.1;
		}
		light*=spotfactor;
	}
	
	
	/***********************************************/
	
	vec4 proj_pos = u_shadow_viewproj * vec4(v_world_position,1.0);	//project our 3D position to the shadowmap

	vec2 shadow_uv = proj_pos.xy / proj_pos.w;	//from homogeneus space to clip space

	shadow_uv = shadow_uv * 0.5 + vec2(0.5);	//from clip space to uv space

	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;	//get point depth (from -1 to 1)
	
	real_depth = real_depth * 0.5 + 0.5;	//normalize from [-1..+1] to [0..+1]

	float shadow_depth = texture( shadowmap, shadow_uv).x;	//read depth from depth buffer in [0..+1]

	//compute final shadow factor by comparing
	float shadow_factor = 1.0;
	
	if( shadow_depth < real_depth )
		shadow_factor = 0.1;
	
	if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		shadow_factor=1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		shadow_factor= 1.0;
	
	light*=shadow_factor;
	
	/***********************************************/
	
	//apply to final pixel color
	//emissive texture
	//vec4 emissive=texture2D( u_emissive_texture, uv);

	//light += emissive.xyz *u_emissive_factor;
	light += u_emissive_factor;

	color.xyz *= light*u_light_intensity; 
	FragColor = color;
}


\multi.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform sampler2D u_metal_roughness;
uniform float u_metalness;
uniform float u_roughness;
uniform bool u_hasmetal;
uniform bool u_hasgamma;

layout(location = 0) out vec4 FragColor;
layout(location = 1) out vec4 NormalColor;
layout(location = 2) out vec4 ExtraColor;

vec3 gamma(vec3 c)
{
	return pow(c,vec3(1.0/2.2));
}

void main()
{
	vec2 uv = v_uv;
	vec4 color = u_color;
	color *= texture( u_texture, uv );

	if(color.a < 0.9 && floor(mod(gl_FragCoord.x,2.0)) !=floor(mod(gl_FragCoord.y,2.0)) )
		discard;

	vec3 N = normalize(v_normal);
	
	//if(u_hasgamma)
		//color.xyz = gamma(color.xyz);
		
	if(u_hasmetal)
	{
		FragColor = vec4(color.rgb, texture(u_metal_roughness, uv).b * u_metalness);
		NormalColor = vec4(N*0.5 + vec3(0.5), texture(u_metal_roughness, uv).g * u_roughness);
	}
	else
	{
		FragColor = vec4(color.rgb, 0.0);
		NormalColor = vec4(N*0.5 + vec3(0.5), 0.0);
	}
}

\deferred.fs

#version 330 core

#define RECIPROCAL_PI 0.3183098861837697
#define PI 3.14159265358979323

uniform vec3 u_camera_position;//camera->eye

uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_extra_texture;
uniform sampler2D u_depth_texture;
uniform vec3 u_emissive_factor;

uniform mat4 u_inverse_viewprojection;
uniform vec2 u_iRes;
uniform bool u_pbr;
uniform bool u_hasgamma;
uniform sampler2D u_ssao;

//pass here all the uniforms required for illumination...

uniform int u_light_type;
uniform float u_spotCutOff;
uniform float u_exponent;
uniform float u_light_maxdist;
uniform float u_light_intensity;

uniform vec3 u_light_vector;
uniform vec3 u_light_position;
uniform vec3 u_ambient_light;
uniform int u_light_num;
uniform vec3 u_light_color;//diffuse

uniform bool u_shadows;
uniform sampler2D shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

uniform bool u_irradiance;
uniform sampler2D u_probes_texture;
uniform vec3 u_irr_end;
uniform vec3 u_irr_start;
uniform float u_irr_normal_distance;
uniform vec3 u_irr_delta;
uniform vec3 u_irr_dims;
uniform float u_num_probes;

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

layout(location = 0) out vec4 FragColor;

vec3 degamma(vec3 c)
{
	return pow(c,vec3(2.2));
}

vec3 gamma(vec3 c)
{
	return pow(c,vec3(1.0/2.2));
}


//********************SHADOW****************************//
float getShadow(vec3 worldpos){
	vec4 proj_pos = u_shadow_viewproj * vec4(worldpos,1.0);	//project our 3D position to the shadowmap

	vec2 shadow_uv = proj_pos.xy / proj_pos.w;	//from homogeneus space to clip space

	shadow_uv = shadow_uv * 0.5 + vec2(0.5);	//from clip space to uv space

	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;	//get point depth (from -1 to 1)
	
	real_depth = real_depth * 0.5 + 0.5;	//normalize from [-1..+1] to [0..+1]

	float shadow_depth = texture( shadowmap, shadow_uv).x;	//read depth from depth buffer in [0..+1]

	//compute final shadow factor by comparing
	float shadow_factor = 1.0;
	
	if( shadow_depth < real_depth )
		shadow_factor = 0.1;
	
	if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		shadow_factor=1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		shadow_factor= 1.0;
	
	return shadow_factor;
}
//***********************************************************//

/*PBR*/
//***********************************************************//

// Normal Distribution Function using GGX Distribution
float D_GGX (	const in float NoH, const in float linearRoughness )
{
	float a2 = linearRoughness * linearRoughness;
	float f = (NoH * NoH) * (a2 - 1.0) + 1.0;
	return a2 / (PI * f * f);
}
// Fresnel term with scalar optimization(f90=1)
vec3 F_Schlick( const in float VoH, const in vec3 f0)
{
	float f = pow(1.0 - VoH, 5.0);
	return f0 + (vec3(1.0) - f0) * f;
}
// Geometry Term: Geometry masking/shadowing due to microfacets
float GGX(float NdotV, float k){
	return NdotV / (NdotV * (1.0 - k) + k);
}
	
float G_Smith( float NdotV, float NdotL, float roughness)
{
	float k = pow(roughness + 1.0, 2.0) / 8.0;
	return GGX(NdotL, k) * GGX(NdotV, k);
}

float lambert(vec3 N, vec3 L)
{
  vec3 nrmN = normalize(N);
  vec3 nrmL = normalize(L);
  float result = dot(nrmN, nrmL);
  return max(result, 0.0);
}


//this is the cook torrance specular reflection model
vec3 specularBRDF( float roughness, vec3 f0, float NoH, float NoV, float NoL, float LoH )
{
	float a = roughness * roughness;

	// Normal Distribution Function
	float D = D_GGX( NoH, a );

	// Fresnel Function
	vec3 F = F_Schlick( LoH, f0 );

	// Visibility Function (shadowing/masking)
	float G = G_Smith( NoV, NoL, roughness );
		
	// Norm factor
	vec3 spec = D * G * F;
	spec /= (4.0 * NoL * NoV + 1e-6);

	return spec;
}

void SHCosineLobe(in vec3 dir, out SH9 sh) //SH9
{
	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;
}

vec3 ComputeSHIrradiance(in vec3 normal, in SH9Color sh)
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine;
	SHCosineLobe(normal, shCosine);
	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += sh.c[i] * shCosine.c[i];

	return irradiance;
}

vec3 difspec(float metalness, float roughness, vec3 N, vec2 uv, vec3 worldpos,vec4 baseColor)
{
	vec3 light = vec3(0.0);//here we can store the total amount of light

	if(u_light_num == 0)
		light += u_ambient_light * texture2D(u_ssao, uv).xyz;//lets add the ambient light first

	vec3 L;
	float spotfactor=0.0;
	float light_distance;
	
	//depending on the light type...
	
	if( u_light_type == 0 ) //directional  light
	{
		L = u_light_vector;
	}
	else //point and spot light
	{
		L = u_light_position - worldpos;//vector from the point to the light
		light_distance = length(L);
		L = normalize(L);//we ignore the light distance for now
	}
	
	//we compute the reflection in base to the color and the metalness
	vec3 f0 = baseColor.xyz * metalness + (vec3(0.5) * (1.0-metalness));//FRESNEL

	//metallic materials do not have diffuse
	vec3 diffuseColor = (1.0 - metalness) * baseColor.xyz;
	
	//Compute dots

	vec3 V = normalize(worldpos - u_camera_position);
	vec3 R = reflect(V, N);//reflected vector
    vec3 H = normalize(L + V);
	float NoH = dot(N, H);
	float NoV = dot(N, V);
	float NoL = dot(N, L);
	float LoH = dot(L, H);

	//compute the specular
	vec3 Fr_d = specularBRDF(  roughness, f0, NoH, NoV, NoL, LoH);

	// Here we use the Burley, but you can replace it by the Lambert.
	// linearRoughness = squared roughness
	vec3 Fd_d = diffuseColor * lambert(N,L); //FD BURLEY SE PUEDE SUSTITUIR POR NDOTL

	//add diffuse and specular reflection
	vec3 direct = Fr_d + Fd_d;
	
	//attenuation
	float att = u_light_maxdist - light_distance;//compute a linear attenuation factor
	att /= u_light_maxdist;//normalize factor
	att = max( att, 0.0 );//ignore negative values
	
	//shadow factor
	float shadow_factor=getShadow(worldpos);

	vec3 lightParams;
	if(u_shadows)
		lightParams = u_light_color * u_light_intensity * att *shadow_factor;
	else
		lightParams = u_light_color * u_light_intensity * att;
	
	if(u_light_type==1){ //spotlight
		
		vec3 D = normalize(u_light_vector);
		float spotCosine = dot(D,-L);
		spotCosine=clamp(spotCosine,0.0,1.0);
		
		if (spotCosine >= u_spotCutOff ) { 
			spotfactor=pow(spotCosine,u_exponent);
		}else{
			spotfactor=0.1;
		}
		lightParams*=spotfactor;
	}

	
	//modulate direct light by light received
	light += direct * lightParams;
	light += u_emissive_factor;

	return light;
}

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes.xy; //extract uvs from pixel screenpos
	vec4 color = texture( u_color_texture, uv );
	if(u_hasgamma)
		color.xyz = gamma(color.xyz);

	float metalness = texture( u_normal_texture, uv ).a;
	float roughness = texture( u_color_texture, uv ).a;

	//normals must be converted from 0..1 to -1..+1
	
	vec3 N = texture( u_normal_texture, uv ).xyz * 2.0 - 1.0;
	N = normalize(N); //always normalize in case of data loss
	
	//reconstruct world position from depth and inv. viewproj
	
	float depth = texture( u_depth_texture, uv ).x;
	vec4 screen_pos = vec4(uv.x*2.0-1.0, uv.y*2.0-1.0, depth*2.0-1.0, 1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_pos;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	//now do your illumination using worldpos and the normal...
	vec3 direct = difspec(metalness, roughness, N, uv, worldpos,color);

	/*IRRADIANCE*/
	vec3 irradiance = vec3(0.0);
	if(u_irradiance)
	{
		//computing nearest probe index based on world position
		vec3 irr_range = u_irr_end - u_irr_start;
		vec3 irr_local_pos = clamp( worldpos - u_irr_start + N * u_irr_normal_distance, vec3(0.0), irr_range );

		//convert from world pos to grid pos
		vec3 irr_norm_pos = irr_local_pos / u_irr_delta;

		//round values as we cannot fetch between rows for now
		vec3 local_indices = round( irr_norm_pos );

		//compute in which row is the probe stored
		float row = local_indices.x + 
		local_indices.y * u_irr_dims.x + 
		local_indices.z * u_irr_dims.x * u_irr_dims.y;

		//find the UV.y coord of that row in the probes texture
		float row_uv = (row + 1.0) / (u_num_probes + 1.0);

		SH9Color sh;

		//fill the coefficients
		const float d_uvx = 1.0 / 9.0;
		for(int i = 0; i < 9; ++i)
		{
			vec2 coeffs_uv = vec2( (float(i)+0.5) * d_uvx, row_uv );
			sh.c[i] = texture( u_probes_texture, coeffs_uv).xyz;
		}

		//now we can use the coefficients to compute the irradiance
		irradiance = ComputeSHIrradiance( N, sh );
	}

	color.xyz *= direct + irradiance;

	//if(u_hasgamma)
		//color.xyz = degamma(color.xyz);

	FragColor = vec4(color.xyz, 1.0);
}

\ssao.fs

#version 330 core

uniform vec2 u_iRes;
uniform sampler2D u_depth_texture;
uniform sampler2D u_normal_texture;
uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform vec3 u_points[64];
uniform float u_bias;

in vec2 v_uv;
out vec4 FragColor;

mat3 cotangent_frame(vec3 N, vec3 p, vec2 uv)
{
	// get edge vectors of the pixel triangle
	vec3 dp1 = dFdx( p );
	vec3 dp2 = dFdy( p );
	vec2 duv1 = dFdx( uv );
	vec2 duv2 = dFdy( uv );
	
	// solve the linear system
	vec3 dp2perp = cross( dp2, N );
	vec3 dp1perp = cross( N, dp1 );
	vec3 T = dp2perp * duv1.x + dp1perp * duv2.x;
	vec3 B = dp2perp * duv1.y + dp1perp * duv2.y;
 
	// construct a scale-invariant frame 
	float invmax = inversesqrt( max( dot(T,T), dot(B,B) ) );
	return mat3( T * invmax, B * invmax, N );
}

void main()
{
	//we want to center the sample in the center of the pixel
	vec2 uv = v_uv + u_iRes * 0.5;

	//read depth from depth buffer
	float depth = texture( u_depth_texture, uv ).x;
	vec3 normal = texture(u_normal_texture, uv).xyz;

	//ignore pixels in the background
	if(depth >= 1.0)
	{
		FragColor = vec4(1.0);
		return;
	}

	//create screenpos with the right depth
	vec4 screen_position = vec4(uv*2.0 - vec2(1.0), depth*2.0 - 1.0,1.0);

	//reproject
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	int samples = 64;
	int num = samples;
	for( int i = 0; i < samples; ++i )
	{
		//to create the matrix33 to convert from tangent to world
		mat3 rotmat = cotangent_frame( normal, worldpos, uv );

		//compute is world position using the random
		vec3 p = worldpos + rotmat * u_points[i] * 10.0;

		//find the uv in the depth buffer of this point
		vec4 proj = u_viewprojection * vec4(p,1.0);
		proj.xy /= proj.w; //convert to clipspace from homogeneous

		//apply a tiny bias to its z before converting to clip-space
		proj.z = (proj.z - u_bias) / proj.w;
		proj.xyz = proj.xyz * 0.5 + vec3(0.5); //to [0..1]

		//read p true depth
		float pdepth = texture( u_depth_texture, proj.xy ).x;

		//compare true depth with its depth
		if( pdepth < proj.z ) //if true depth smaller, is inside
			num--; //remove this point from the list of visible
	}

	//finally, compute the AO factor accordingly
	float ao = float(num) / float(samples);
	ao = pow(ao, 2);

	FragColor = vec4(ao);
}

\blur.fs

#version 330 core

uniform vec2 u_offset;
uniform sampler2D u_texture;

in vec2 v_uv;
out vec4 FragColor;

void main(){

	//we want to center the sample in the center of the pixel
	vec2 uv = v_uv ;
	vec4 color =vec4(0.0);
	for (int i=-2;i<=2;i++)
	{
		for (int j=-2;j<=2;j++)
		{
			color += texture2D(u_texture, uv + u_offset * vec2(i,j) + vec2(0.5) * u_offset);
		}
	}

	color/=25.0;
	FragColor=vec4(color);
}



\depth.fs

#version 330 core

uniform vec2 u_camera_nearfar;
uniform sampler2D u_texture; //depth map
in vec2 v_uv;
out vec4 FragColor;

void main()
{
	float n = u_camera_nearfar.x;
	float f = u_camera_nearfar.y;
	float z = texture2D(u_texture,v_uv).x;
	float color = n * (z + 1.0) / (f + n - z * (f - n));
	FragColor = vec4(color);
}


\instanced.vs

#version 330 core

in vec3 a_vertex;
in vec3 a_normal;
in vec2 a_uv;

in mat4 u_model;

uniform vec3 u_camera_pos;

uniform mat4 u_viewprojection;

//this will store the color for the pixel shader
out vec3 v_position;
out vec3 v_world_position;
out vec3 v_normal;
out vec2 v_uv;

void main()
{	
	//calcule the normal in camera space (the NormalMatrix is like ViewMatrix but without traslation)
	v_normal = (u_model * vec4( a_normal, 0.0) ).xyz;
	
	//calcule the vertex in object space
	v_position = a_vertex;
	v_world_position = (u_model * vec4( a_vertex, 1.0) ).xyz;
	
	//store the texture coordinates
	v_uv = a_uv;

	//calcule the position of the vertex using the matrices
	gl_Position = u_viewprojection * vec4( v_world_position, 1.0 );
}

\probe.fs

#version 330 core

in vec3 v_normal;

uniform mat4 u_viewprojection;
uniform vec3 u_camera_position;
uniform mat4 u_model;
uniform vec3 u_coeffs[9];

out vec4 FragColor;

const float Pi = 3.141592654;
const float CosineA0 = Pi;
const float CosineA1 = (2.0 * Pi) / 3.0;
const float CosineA2 = Pi * 0.25;
struct SH9 { float c[9]; }; //to store weights
struct SH9Color { vec3 c[9]; }; //to store colors

SH9 SHCosineLobe(vec3 dir) //SH9
{
	SH9 sh;

	// Band 0
	sh.c[0] = 0.282095 * CosineA0;
	// Band 1
	sh.c[1] = 0.488603 * dir.y * CosineA1; 
	sh.c[2] = 0.488603 * dir.z * CosineA1;
	sh.c[3] = 0.488603 * dir.x * CosineA1;
	// Band 2
	sh.c[4] = 1.092548 * dir.x * dir.y * CosineA2;
	sh.c[5] = 1.092548 * dir.y * dir.z * CosineA2;
	sh.c[6] = 0.315392 * (3.0 * dir.z * dir.z - 1.0) * CosineA2;
	sh.c[7] = 1.092548 * dir.x * dir.z * CosineA2;
	sh.c[8] = 0.546274 * (dir.x * dir.x - dir.y * dir.y) * CosineA2;

	return sh;
}


void main()
{
	// Compute the cosine lobe in SH, oriented about the normal direction
	SH9 shCosine = SHCosineLobe(normalize(v_normal));

	// Compute the SH dot product to get irradiance
	vec3 irradiance = vec3(0.0);
	for(int i = 0; i < 9; ++i)
		irradiance += u_coeffs[i] * shCosine.c[i];

	FragColor = vec4(irradiance, 1.0);
}

\skybox.fs

#version 330 core
in vec3 v_world_position;
in vec3 v_normal;

uniform samplerCube u_texture;
uniform vec3 u_camera_position;

out vec4 FragColor;

void main()
{
	vec3 N = normalize( v_normal );
	vec3 V = normalize( v_world_position - u_camera_position );
	//vec3 R = reflect( V, N );

	FragColor = textureLod( u_texture, -V, 0.0 )*1.0;
}

\ref_probes.fs

#version 330 core
in vec3 v_world_position;
in vec3 v_normal;

uniform samplerCube u_texture;
uniform vec3 u_camera_position;

out vec4 FragColor;

void main()
{
	vec3 N = normalize( v_normal );
	vec3 V = normalize( v_world_position - u_camera_position );
	vec3 R = reflect( V, N );
	FragColor = textureLod( u_texture, R, 0.0 );
}


\tonemapper.fs

#version 330 core

in vec2 v_uv;

uniform sampler2D u_texture;
uniform float u_scale;
uniform float u_average_lum;
uniform float u_lumwhite2;
uniform float u_igamma;

out vec4 FragColor;

vec3 RGB2xyY (vec3 rgb)
{
	const mat3 RGB2XYZ = mat3(0.4124, 0.3576, 0.1805,
							   0.2126, 0.7152, 0.0722,
							   0.0193, 0.1192, 0.9505);
	vec3 XYZ = RGB2XYZ * rgb;
	float f = (XYZ.x + XYZ.y + XYZ.z);

	return vec3(XYZ.x / f,
				XYZ.y / f,
				XYZ.y);
}

vec3 applyTonemapper(vec3 color) {
	vec3 rgb = color;

	float lum = dot(rgb, vec3(0.2126, 0.7152, 0.0722));
	float L = (u_scale / u_average_lum) * lum;
	float Ld = (L * (1.0 + L / u_lumwhite2)) / (1.0 + L);

	rgb = (rgb / lum) * Ld;
	rgb = max(rgb,vec3(0.001));
	rgb = pow( rgb, vec3( u_igamma ) );

	return rgb;
}

void main()
{
	vec4 color = texture2D(u_texture, v_uv);
	color.xyz = applyTonemapper (color.xyz);
	FragColor = color;
}

\volumetricdir.fs

#version 330 core

uniform sampler2D u_depth_texture;
uniform float u_time;
uniform vec3 u_ambient_light;
uniform vec3 u_camera_position;
uniform vec2 u_iRes;
uniform mat4 u_inverse_viewprojection;

uniform vec3 u_light_color;

uniform sampler2D shadowmap;
uniform mat4 u_shadow_viewproj;
uniform float u_shadow_bias;

uniform sampler2D u_noise;
uniform vec3 u_rand;

uniform float u_sample_density;

in vec2 v_uv;
out vec4 FragColor;

float getShadow(vec3 worldpos)
{
	vec4 proj_pos = u_shadow_viewproj * vec4(worldpos,1.0);	//project our 3D position to the shadowmap

	vec2 shadow_uv = proj_pos.xy / proj_pos.w;	//from homogeneus space to clip space

	shadow_uv = shadow_uv * 0.5 + vec2(0.5);	//from clip space to uv space

	float real_depth = (proj_pos.z - u_shadow_bias) / proj_pos.w;	//get point depth (from -1 to 1)
	
	real_depth = real_depth * 0.5 + 0.5;	//normalize from [-1..+1] to [0..+1]

	float shadow_depth = texture( shadowmap, shadow_uv).x;	//read depth from depth buffer in [0..+1]

	//compute final shadow factor by comparing
	float shadow_factor = 1.0;
	
	if( shadow_depth < real_depth )
		shadow_factor = 0.1;
	
	if(	shadow_uv.x < 0.0 || shadow_uv.x > 1.0 ||shadow_uv.y < 0.0 || shadow_uv.y > 1.0)
		shadow_factor=1.0;

	//it is before near or behind far plane
	if(real_depth < 0.0 || real_depth > 1.0)
		shadow_factor= 1.0;
	
	return shadow_factor;
}

void main()
{
	const float SAMPLES = 64.0;

	vec2 uv = gl_FragCoord.xy * u_iRes.xy;
	float depth = texture(u_depth_texture, uv).x;

	vec4 screen_position = vec4(uv*2.0 - vec2(1.0), depth*2.0 - 1.0,1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	vec3 raydir = worldpos - u_camera_position;
	float noise = texture(u_noise, uv * 2.0 + u_rand.xy).x;
	raydir /= SAMPLES;

	vec3 current_pos = u_camera_position + raydir * noise;

	vec3 color = vec3(0.0);
	float total_density = 0.0;

	for(int i = 0; i < SAMPLES; i++)
	{
		float shadow_factor = getShadow(current_pos);
		color += u_sample_density * shadow_factor * u_light_color;
		total_density += u_sample_density * shadow_factor;
		if(total_density >= 1.0)
			break;
		current_pos += raydir;
	}

	FragColor = vec4(color, total_density);
}

\deferred_reflections.fs

#version 330 core

//in vec3 v_normal;

uniform mat4 u_inverse_viewprojection;
uniform mat4 u_viewprojection;
uniform sampler2D u_color_texture;
uniform sampler2D u_normal_texture;
uniform sampler2D u_depth_texture;
uniform vec2 u_iRes;
uniform vec3 u_camera_position;
uniform samplerCube u_environment_texture;
uniform sampler2D u_ao_texture;

in vec2 v_uv;
out vec4 FragColor;

void main()
{
	
	vec2 uv = gl_FragCoord.xy * u_iRes;

	float depth = texture( u_depth_texture, uv ).x;
	vec4 normal = texture(u_normal_texture, uv);
	vec4 color = texture(u_color_texture, uv);

	if(depth==1.0)
		discard;

	vec3 N = normalize( normal.xyz * 2.0 - 1.0 );
	vec4 screen_position = vec4(uv * 2.0 - vec2(1.0), depth * 2.0 - 1.0,1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;

	float metalness = normal.w;
	float roughness = color.w;

	vec3 V = normalize( u_camera_position - worldpos );
	vec3 R = reflect( V, N );

	vec3 reflection = color.xyz * textureLod(u_environment_texture, R,roughness * 5.0 ).xyz;

	FragColor = vec4( reflection, metalness);
}

\planar_ref.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;
in vec4 v_color;

uniform vec4 u_color;
uniform sampler2D u_texture;
uniform float u_time;
uniform float u_alpha_cutoff;

uniform vec2 u_iRes;

out vec4 FragColor;

void main()
{
	vec2 uv = gl_FragCoord.xy * u_iRes;
	uv.x = 1.0-uv.x;

	vec4 color = u_color;

	color *= texture( u_texture, uv);

	if(color.a < u_alpha_cutoff)
		discard;

	//FragColor = vec4(1.0);
	FragColor = color;
}

\decal.fs

#version 330 core

in vec3 v_position;
in vec3 v_world_position;
in vec3 v_normal;
in vec2 v_uv;

uniform sampler2D u_texture;
uniform sampler2D u_depth_texture;
uniform mat4 u_inverse_viewprojection;
uniform mat4 u_imodel;
uniform vec3 u_camera_position;
uniform vec2 u_iRes;

layout(location = 0) out vec4 ColorBuffer;

void main()
{

	vec2 uv = gl_FragCoord.xy * u_iRes;

	float depth = texture( u_depth_texture, uv ).x;
	if(depth > 1.0)
	{
		discard;
	}

	vec4 screen_position = vec4(uv * 2.0 - vec2(1.0), depth * 2.0 - 1.0,1.0);
	vec4 proj_worldpos = u_inverse_viewprojection * screen_position;
	vec3 worldpos = proj_worldpos.xyz / proj_worldpos.w;
	vec3 V = normalize(worldpos - u_camera_position);

	vec3 decal_pos = (u_imodel * vec4(worldpos, 1.0)).xyz;
	vec2 uv_decal = decal_pos.xz * 0.5 + vec2(0.5);
	if(uv_decal.x < 0.0 || uv_decal.x > 1.0 || uv_decal.y > 1.0 || uv_decal.y < 0.0 )
		discard;

	vec4 color = texture(u_texture, uv_decal);

	ColorBuffer = color;
}